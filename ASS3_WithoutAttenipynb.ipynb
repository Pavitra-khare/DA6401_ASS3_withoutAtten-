{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8190591,
          "sourceType": "datasetVersion",
          "datasetId": 4850432
        },
        {
          "sourceId": 8303996,
          "sourceType": "datasetVersion",
          "datasetId": 4933043
        },
        {
          "sourceId": 8304151,
          "sourceType": "datasetVersion",
          "datasetId": 4933099
        },
        {
          "sourceId": 8304593,
          "sourceType": "datasetVersion",
          "datasetId": 4933272
        },
        {
          "sourceId": 8407265,
          "sourceType": "datasetVersion",
          "datasetId": 5003045
        },
        {
          "sourceId": 11806983,
          "sourceType": "datasetVersion",
          "datasetId": 7415098
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavitra-khare/DA6401_ASS3_withoutAtten-/blob/main/ASS3_WithoutAttenipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and login"
      ],
      "metadata": {
        "id": "VejTsKhNLm2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install wandb\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-05-17T22:49:14.259702Z",
          "iopub.execute_input": "2025-05-17T22:49:14.260309Z",
          "iopub.status.idle": "2025-05-17T22:49:14.263472Z",
          "shell.execute_reply.started": "2025-05-17T22:49:14.260285Z",
          "shell.execute_reply": "2025-05-17T22:49:14.262655Z"
        },
        "id": "ea9Qw2XX03Tv",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import warnings\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "torch.cuda.empty_cache()\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import torch.utils.data as data\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "mUM6KgAM-oT1",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T22:49:14.264732Z",
          "iopub.execute_input": "2025-05-17T22:49:14.264988Z",
          "iopub.status.idle": "2025-05-17T22:49:14.282471Z",
          "shell.execute_reply.started": "2025-05-17T22:49:14.264966Z",
          "shell.execute_reply": "2025-05-17T22:49:14.281673Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key=\"71aebd5eed3e9b3e37a5a3c4658f5433375d97dc\")\n"
      ],
      "metadata": {
        "id": "KZ1QyWsV-oUN",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T22:49:14.283697Z",
          "iopub.execute_input": "2025-05-17T22:49:14.283954Z",
          "iopub.status.idle": "2025-05-17T22:49:14.644451Z",
          "shell.execute_reply.started": "2025-05-17T22:49:14.283931Z",
          "shell.execute_reply": "2025-05-17T22:49:14.643785Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "HwQHFp9POlu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "'''Location of your CSV file (Extracted file)\n",
        "Location of your CSV file if on kaggle than zip file is fine'''\n",
        "\n",
        "trainFilepath=\"/kaggle/input/myinput/aksharantar_sampled/hin/hin_train.csv\"\n",
        "valFilePath=\"/kaggle/input/myinput/aksharantar_sampled/hin/hin_valid.csv\"\n",
        "testFilePath=\"/kaggle/input/myinput/aksharantar_sampled/hin/hin_test.csv\""
      ],
      "metadata": {
        "id": "R-OebR_K-oUE",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T22:49:14.645158Z",
          "iopub.execute_input": "2025-05-17T22:49:14.645816Z",
          "iopub.status.idle": "2025-05-17T22:49:14.649678Z",
          "shell.execute_reply.started": "2025-05-17T22:49:14.645792Z",
          "shell.execute_reply": "2025-05-17T22:49:14.649118Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file_0(filepath):\n",
        "    def process_row(text_row):\n",
        "        return list(text_row)\n",
        "\n",
        "    def collect_characters(reader_obj):\n",
        "        all_chars = []\n",
        "        for entry in reader_obj:\n",
        "            all_chars += process_row(entry[0])\n",
        "        return all_chars\n",
        "\n",
        "    with open(filepath, mode='r') as file_handle:\n",
        "        csv_reader = csv.reader(file_handle)\n",
        "        return collect_characters(csv_reader)\n"
      ],
      "metadata": {
        "id": "lL5546mp03Tw",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T22:49:14.651181Z",
          "iopub.execute_input": "2025-05-17T22:49:14.651435Z",
          "iopub.status.idle": "2025-05-17T22:49:14.664179Z",
          "shell.execute_reply.started": "2025-05-17T22:49:14.651420Z",
          "shell.execute_reply": "2025-05-17T22:49:14.663561Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# trainFilepath = '/kaggle/input/aksharantar-sampled/aksharantar_sampled/hin/hin_train.csv'\n",
        "\n",
        "\n",
        "chars = read_file_0(trainFilepath)\n",
        "setChar=set(chars)\n",
        "setChar.add('|')\n",
        "setOfchar = list(setChar)\n",
        "\n",
        "# Create the association between characters and their corresponding integer indices\n",
        "char_to_idx_latin= {char: i+1 for i, char in enumerate(setOfchar)}"
      ],
      "metadata": {
        "id": "MuY2sxX_03Tx",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T22:49:14.664952Z",
          "iopub.execute_input": "2025-05-17T22:49:14.665215Z",
          "iopub.status.idle": "2025-05-17T22:49:14.739111Z",
          "shell.execute_reply.started": "2025-05-17T22:49:14.665193Z",
          "shell.execute_reply": "2025-05-17T22:49:14.738637Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file_1(trainFilepath):\n",
        "    def extract_chars(text):\n",
        "        return list(text)\n",
        "\n",
        "    def accumulate(reader_obj):\n",
        "        buffer = []\n",
        "        for entry in reader_obj:\n",
        "            buffer += extract_chars(entry[1])\n",
        "        return buffer\n",
        "\n",
        "    with open(trainFilepath, 'r') as file_stream:\n",
        "        csv_rows = csv.reader(file_stream)\n",
        "        return accumulate(csv_rows)"
      ],
      "metadata": {
        "id": "_Fu5-CC603Tx",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T22:49:14.739701Z",
          "iopub.execute_input": "2025-05-17T22:49:14.740009Z",
          "iopub.status.idle": "2025-05-17T22:49:14.744580Z",
          "shell.execute_reply.started": "2025-05-17T22:49:14.739991Z",
          "shell.execute_reply": "2025-05-17T22:49:14.743922Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "maxLenDev=0\n",
        "\n",
        "chars = read_file_1(trainFilepath)\n",
        "setChar=set(chars)\n",
        "setChar.add('|')\n",
        "setOfchar = list(setChar)\n",
        "\n",
        "charToIndLang ={char: i+1 for i, char in enumerate(setOfchar)}"
      ],
      "metadata": {
        "id": "BsSPFp2f-oUF",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T22:49:14.745284Z",
          "iopub.execute_input": "2025-05-17T22:49:14.745557Z",
          "iopub.status.idle": "2025-05-17T22:49:14.822937Z",
          "shell.execute_reply.started": "2025-05-17T22:49:14.745539Z",
          "shell.execute_reply": "2025-05-17T22:49:14.822271Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with open(trainFilepath, 'r') as csv_file:\n",
        "    reader = csv.reader(csv_file)\n",
        "    max_length = 0\n",
        "\n",
        "    def update_max(current_max, candidate):\n",
        "        return candidate if candidate > current_max else current_max\n",
        "\n",
        "    for record in reader:\n",
        "        length = len(record[0])\n",
        "        max_length = update_max(max_length, length)\n",
        "\n",
        "    maxLenEng = max_length"
      ],
      "metadata": {
        "id": "YnH-KUwf-oUH",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T22:49:14.823870Z",
          "iopub.execute_input": "2025-05-17T22:49:14.824137Z",
          "iopub.status.idle": "2025-05-17T22:49:14.871037Z",
          "shell.execute_reply.started": "2025-05-17T22:49:14.824105Z",
          "shell.execute_reply": "2025-05-17T22:49:14.870567Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with open(trainFilepath, 'r') as csv_stream:\n",
        "    reader_obj = csv.reader(csv_stream)\n",
        "    longest = 0\n",
        "\n",
        "    def get_larger(a, b):\n",
        "        return b if b > a else a\n",
        "\n",
        "    for line in reader_obj:\n",
        "        current_length = len(line[1])\n",
        "        longest = get_larger(longest, current_length)\n",
        "\n",
        "    maxLenDev = longest"
      ],
      "metadata": {
        "id": "_CT0LTQL-oUI",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T22:49:14.871609Z",
          "iopub.execute_input": "2025-05-17T22:49:14.871784Z",
          "iopub.status.idle": "2025-05-17T22:49:14.915759Z",
          "shell.execute_reply.started": "2025-05-17T22:49:14.871770Z",
          "shell.execute_reply": "2025-05-17T22:49:14.915089Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "characters in words -> indices"
      ],
      "metadata": {
        "id": "tsO0M3gVFjJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_characters_to_indices(word, dictionary):\n",
        "    def safe_lookup(char):\n",
        "        return dictionary[char] if char in dictionary else -1\n",
        "\n",
        "    mapped = [safe_lookup(ch) for ch in word]\n",
        "    filtered = list(filter(lambda idx: idx >= 0, mapped))\n",
        "    return filtered"
      ],
      "metadata": {
        "id": "sheJBSGMEUAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_sequence_length(indices, maximumLength):\n",
        "    current_length = len(indices)\n",
        "\n",
        "    def trim(seq, length):\n",
        "        return seq[:length]\n",
        "\n",
        "    def pad(seq, total_length):\n",
        "        padding_needed = total_length - len(seq)\n",
        "        return seq + [0] * padding_needed\n",
        "\n",
        "    if current_length > maximumLength:\n",
        "        return trim(indices, maximumLength)\n",
        "    elif current_length < maximumLength:\n",
        "        return pad(indices, maximumLength)\n",
        "    return indices\n"
      ],
      "metadata": {
        "id": "WX8Z8YnYEihz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_indices_to_tensor(indices, dictionary):\n",
        "    token = dictionary.get('|', 0)\n",
        "\n",
        "    def add_delimiters(seq, token_id):\n",
        "        return [token_id] + seq + [token_id]\n",
        "\n",
        "    sequence = add_delimiters(indices, token)\n",
        "    tensor_obj = torch.tensor(sequence, device=device)\n",
        "    return tensor_obj"
      ],
      "metadata": {
        "id": "XtOqUF5rEjVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_word_to_indices(word, maximumLength, dict):\n",
        "    char_ids = convert_characters_to_indices(word, dict)\n",
        "\n",
        "    def standardize_length(seq, target_len):\n",
        "        return adjust_sequence_length(seq, target_len)\n",
        "\n",
        "    resized = standardize_length(char_ids, maximumLength)\n",
        "    tensor_out = convert_indices_to_tensor(resized, dict)\n",
        "    return tensor_out\n"
      ],
      "metadata": {
        "id": "-KtrvJ-eEnm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_tensor_to_generated_sequences(sequence):\n",
        "    tokens = sequence.split()\n",
        "\n",
        "    def concatenate(tokens):\n",
        "        return ''.join(tokens)\n",
        "\n",
        "    def compute_total_length(tokens):\n",
        "        return sum(len(token) for token in tokens)\n",
        "\n",
        "    combined = concatenate(tokens)\n",
        "    total_len = compute_total_length(tokens)\n",
        "\n",
        "    return combined, total_len"
      ],
      "metadata": {
        "id": "G_7gFP9rEtAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assemble_tensor(final_tensor, partition_size=1):\n",
        "    def safe_partition_size(size):\n",
        "        return max(1, size)\n",
        "\n",
        "    chunk_size = safe_partition_size(partition_size)\n",
        "    segments = [final_tensor[idx:idx + chunk_size] for idx in range(0, len(final_tensor), chunk_size)]\n",
        "\n",
        "    return segments"
      ],
      "metadata": {
        "id": "D_RlTwkJE-AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assemble_assigned_generated_seq(path):\n",
        "    combined_seq, total_chars = assign_tensor_to_generated_sequences(path)\n",
        "\n",
        "    def determine_chunk_size(length, divisor=4):\n",
        "        return max(1, length // divisor)\n",
        "\n",
        "    segment_length = determine_chunk_size(total_chars)\n",
        "    partitioned = assemble_tensor(combined_seq, segment_length)\n",
        "\n",
        "    return partitioned\n"
      ],
      "metadata": {
        "id": "xZiXxSCzFK4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_indices(row):\n",
        "    src_text = row[0]\n",
        "    tgt_text = row[1]\n",
        "\n",
        "    def build_indexed_tensor(text, max_len, char_map):\n",
        "        return convert_word_to_indices(text, max_len, char_map)\n",
        "\n",
        "    source_tensor = build_indexed_tensor(src_text, maxLenEng, char_to_idx_latin)\n",
        "    target_tensor = build_indexed_tensor(tgt_text, maxLenDev, charToIndLang)\n",
        "\n",
        "    return source_tensor, target_tensor\n"
      ],
      "metadata": {
        "id": "IMihcYLNFLf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CnuWgWf1FNY5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}